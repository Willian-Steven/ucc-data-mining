{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6e12247f-61dc-4999-867e-02abbd9fb37f",
   "metadata": {},
   "source": [
    "Basado en la siguiente estructura de datos de un archivo .csv, realizar los siguientes ejercicios de DeepLearning\n",
    "en el lenguaje python y librerias como Scikit Learn, Keras, Shap, Pytorch:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "029a6588-c9ae-4045-af99-177d10917f64",
   "metadata": {},
   "source": [
    "1. Predicción de Clasificación Temporal con Redes Neuronales Recurrentes (RNN)\n",
    "* Este ejercicio implica predecir la ocurrencia de un cierto tipo de crimen en\n",
    "función de la fecha y hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbf1e29-9793-43aa-9e89-ba00e5bded38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 02:54:49.893887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 02:54:54.871557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.2177 - loss: 2.4126 - val_accuracy: 0.2251 - val_loss: 2.3402\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.2257 - loss: 2.3442 - val_accuracy: 0.2284 - val_loss: 2.3365\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.2259 - loss: 2.3397 - val_accuracy: 0.2223 - val_loss: 2.3351\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - accuracy: 0.2282 - loss: 2.3372 - val_accuracy: 0.2275 - val_loss: 2.3308\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.2253 - loss: 2.3362 - val_accuracy: 0.2292 - val_loss: 2.3275\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - accuracy: 0.2279 - loss: 2.3316 - val_accuracy: 0.2294 - val_loss: 2.3261\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.2273 - loss: 2.3297 - val_accuracy: 0.2297 - val_loss: 2.3299\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.2284 - loss: 2.3296 - val_accuracy: 0.2302 - val_loss: 2.3257\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7ms/step - accuracy: 0.2285 - loss: 2.3299 - val_accuracy: 0.2298 - val_loss: 2.3244\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.2307 - loss: 2.3264 - val_accuracy: 0.2297 - val_loss: 2.3243\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 10ms/step - accuracy: 0.2300 - loss: 2.3273 - val_accuracy: 0.2314 - val_loss: 2.3233\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 11ms/step - accuracy: 0.2311 - loss: 2.3242 - val_accuracy: 0.2311 - val_loss: 2.3234\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 11ms/step - accuracy: 0.2306 - loss: 2.3233 - val_accuracy: 0.2318 - val_loss: 2.3217\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 11ms/step - accuracy: 0.2306 - loss: 2.3248 - val_accuracy: 0.2314 - val_loss: 2.3218\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 11ms/step - accuracy: 0.2315 - loss: 2.3224 - val_accuracy: 0.2311 - val_loss: 2.3225\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 11ms/step - accuracy: 0.2321 - loss: 2.3244 - val_accuracy: 0.2319 - val_loss: 2.3215\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 11ms/step - accuracy: 0.2326 - loss: 2.3245 - val_accuracy: 0.2309 - val_loss: 2.3213\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 11ms/step - accuracy: 0.2311 - loss: 2.3248 - val_accuracy: 0.2315 - val_loss: 2.3213\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 12ms/step - accuracy: 0.2299 - loss: 2.3227 - val_accuracy: 0.2314 - val_loss: 2.3210\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 12ms/step - accuracy: 0.2311 - loss: 2.3206 - val_accuracy: 0.2305 - val_loss: 2.3214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4c8f9a8d50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "# Preprocesamiento de datos\n",
    "\n",
    "data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'])\n",
    "\n",
    "data['HOUR'] = data['DATE OF OCCURRENCE'].dt.hour\n",
    "data['DAY_OF_WEEK'] = data['DATE OF OCCURRENCE'].dt.dayofweek\n",
    "data['MONTH'] = data['DATE OF OCCURRENCE'].dt.month\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['HOUR', 'DAY_OF_WEEK', 'MONTH']].values\n",
    "y = data['PRIMARY DESCRIPTION']\n",
    "# Codificar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Construir la red neuronal recurrente (LSTM)\n",
    "model = Sequential([\n",
    " LSTM(64, input_shape=(X_train.shape[1], 1), activation='relu', return_sequences=True),\n",
    " LSTM(32, activation='relu'),\n",
    " Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Ajustar el modelo\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db20ca4a-edf2-4601-a493-522abbfdfe6b",
   "metadata": {},
   "source": [
    "2. Predicción de Series Temporales con Redes Neuronales Convolucionales (CNN)\n",
    "* Este ejercicio implica predecir la ocurrencia de un tipo de crimen utilizando datos\n",
    "de series temporales como entrada a una CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d192a286-b8d1-4e6f-86b1-16529af2932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - accuracy: 0.2174 - loss: 2.4176 - val_accuracy: 0.2205 - val_loss: 2.3939\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2221 - loss: 2.3652 - val_accuracy: 0.2205 - val_loss: 2.3990\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2229 - loss: 2.3652 - val_accuracy: 0.2205 - val_loss: 2.3757\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.2205 - loss: 2.3699 - val_accuracy: 0.2205 - val_loss: 2.3783\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - accuracy: 0.2226 - loss: 2.3619 - val_accuracy: 0.2205 - val_loss: 2.3754\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2212 - loss: 2.3631 - val_accuracy: 0.2205 - val_loss: 2.3793\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2225 - loss: 2.3654 - val_accuracy: 0.2205 - val_loss: 2.3770\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2210 - loss: 2.3670 - val_accuracy: 0.2205 - val_loss: 2.3864\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2224 - loss: 2.3617 - val_accuracy: 0.2205 - val_loss: 2.3814\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2203 - loss: 2.3642 - val_accuracy: 0.2205 - val_loss: 2.3788\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2225 - loss: 2.3623 - val_accuracy: 0.2205 - val_loss: 2.3789\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2218 - loss: 2.3621 - val_accuracy: 0.2205 - val_loss: 2.3785\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2219 - loss: 2.3663 - val_accuracy: 0.2205 - val_loss: 2.3837\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2233 - loss: 2.3641 - val_accuracy: 0.2205 - val_loss: 2.3891\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2231 - loss: 2.3618 - val_accuracy: 0.2205 - val_loss: 2.3795\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2218 - loss: 2.3623 - val_accuracy: 0.2205 - val_loss: 2.3806\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2233 - loss: 2.3608 - val_accuracy: 0.2205 - val_loss: 2.3794\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2211 - loss: 2.3631 - val_accuracy: 0.2205 - val_loss: 2.3786\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2206 - loss: 2.3682 - val_accuracy: 0.2205 - val_loss: 2.3841\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.2205 - loss: 2.3655 - val_accuracy: 0.2205 - val_loss: 2.3839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4c995ca950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "# Asegúrate de que los datos estén ordenados cronológicamente\n",
    "data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'])\n",
    "data = data.sort_values(by='DATE OF OCCURRENCE')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['DATE OF OCCURRENCE']].values\n",
    "y = data['PRIMARY DESCRIPTION']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(len(y.unique()), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Ajustar etiquetas:\n",
    "# Convertir las etiquetas a números enteros\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ajustar el modelo\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test, y_test_encoded))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a993632-73c8-4883-b3a0-ea5d54cdbcae",
   "metadata": {},
   "source": [
    "3. Predicción de Series Temporales con Redes Neuronales Auto-Recurrentes (ARNN)\n",
    "* Este ejercicio implica predecir la ocurrencia de un tipo de crimen utilizando datos\n",
    "de series temporales y una red neuronal auto-recurrente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39802c5-0d27-4c3b-b1ec-ff67011d76f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.2192 - loss: 2.4313 - val_accuracy: 0.2205 - val_loss: 2.3893\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2214 - loss: 2.3663 - val_accuracy: 0.2205 - val_loss: 2.3879\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2206 - loss: 2.3676 - val_accuracy: 0.2205 - val_loss: 2.3840\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2210 - loss: 2.3656 - val_accuracy: 0.2205 - val_loss: 2.3802\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2218 - loss: 2.3658 - val_accuracy: 0.2205 - val_loss: 2.3817\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.2222 - loss: 2.3642 - val_accuracy: 0.2205 - val_loss: 2.3811\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - accuracy: 0.2228 - loss: 2.3649 - val_accuracy: 0.2205 - val_loss: 2.3811\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2205 - loss: 2.3685 - val_accuracy: 0.2205 - val_loss: 2.3816\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2222 - loss: 2.3636 - val_accuracy: 0.2205 - val_loss: 2.3829\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2202 - loss: 2.3650 - val_accuracy: 0.2205 - val_loss: 2.3794\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2221 - loss: 2.3636 - val_accuracy: 0.2205 - val_loss: 2.3840\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2218 - loss: 2.3641 - val_accuracy: 0.2205 - val_loss: 2.3780\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2216 - loss: 2.3662 - val_accuracy: 0.2205 - val_loss: 2.3903\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2202 - loss: 2.3649 - val_accuracy: 0.2205 - val_loss: 2.3828\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2218 - loss: 2.3624 - val_accuracy: 0.2205 - val_loss: 2.3920\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2234 - loss: 2.3632 - val_accuracy: 0.2205 - val_loss: 2.3873\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2221 - loss: 2.3664 - val_accuracy: 0.2205 - val_loss: 2.3816\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2211 - loss: 2.3653 - val_accuracy: 0.2205 - val_loss: 2.3954\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2206 - loss: 2.3634 - val_accuracy: 0.2205 - val_loss: 2.3846\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - accuracy: 0.2236 - loss: 2.3620 - val_accuracy: 0.2205 - val_loss: 2.3898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4c9094f4d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "# Preprocesamiento de datos\n",
    "# Asegúrate de que los datos estén ordenados cronológicamente\n",
    "data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "# data['DATE OF OCCURRENCE'] = pd.to_datetime(data['DATE OF OCCURRENCE'])\n",
    "data = data.sort_values(by='DATE OF OCCURRENCE')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['DATE OF OCCURRENCE']].values\n",
    "y = data['PRIMARY DESCRIPTION']\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Ajustar las dimensiones para la entrada de ARNN (reshape)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "# Construir la red neuronal auto-recurrente (ARNN)\n",
    "model = Sequential([\n",
    " SimpleRNN(64, activation='relu', return_sequences=True),\n",
    " SimpleRNN(32, activation='relu'),\n",
    " Dense(len(y.unique()), activation='softmax')\n",
    "])\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convertir etiquetas de texto a valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Ajustar el modelo con las etiquetas numéricas\n",
    "model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Ajustar el modelo\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f4ad218-ce5c-407c-abe2-5316b25db218",
   "metadata": {},
   "source": [
    "4. Predicción de Valores Continuos con Redes Neuronales Profundas (DNN)\n",
    "* Este ejercicio implica predecir la latitud y longitud de la ubicación de un crimen\n",
    "utilizando una red neuronal profunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26645ecd-3a6d-47a2-bfa9-9f9408ac48b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 1/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "\u001b[1m6469/6469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4c4f429a50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "# Seleccionar características y etiquetas\n",
    "X = data[['X COORDINATE', 'Y COORDINATE']].values\n",
    "y_latitude = data['LATITUDE'].values\n",
    "y_longitude = data['LONGITUDE'].values\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_lat_train, y_lat_test, y_long_train, y_long_test = train_test_split( X, y_latitude, y_longitude, test_size=0.2, random_state=42)\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Construir la red neuronal profunda (DNN)\n",
    "model_lat = Sequential([\n",
    " Dense(64, activation='relu'),\n",
    " Dense(32, activation='relu'),\n",
    " Dense(1)\n",
    "])\n",
    "\n",
    "model_long = Sequential([\n",
    " Dense(64, activation='relu'),\n",
    " Dense(32, activation='relu'),\n",
    " Dense(1)\n",
    "])\n",
    "# Compilar el modelo\n",
    "model_lat.compile(optimizer='adam', loss='mse')\n",
    "model_long.compile(optimizer='adam', loss='mse')\n",
    "# Ajustar el modelo\n",
    "model_lat.fit(X_train, y_lat_train, epochs=20, batch_size=32, validation_data=(X_test, y_lat_test))\n",
    "model_long.fit(X_train, y_long_train, epochs=20, batch_size=32, validation_data=(X_test, y_long_test))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "204f788e-c511-4316-96d6-dcf6cb3f71ab",
   "metadata": {},
   "source": [
    "5. Predicción de Texto usando Redes Neuronales Recurrentes (RNN)\n",
    "* Este ejercicio implica predecir la descripción de un crimen basándose en su título\n",
    "y ubicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b90a77f-5461-4e5a-aecc-5f0a0dc459ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.1139 - loss: 3.8570 - val_accuracy: 0.1179 - val_loss: 3.6639\n",
      "Epoch 2/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.1163 - loss: 3.6666 - val_accuracy: 0.1179 - val_loss: 3.6562\n",
      "Epoch 3/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.1161 - loss: 3.6594 - val_accuracy: 0.1179 - val_loss: 3.6531\n",
      "Epoch 4/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.1163 - loss: 3.6613 - val_accuracy: 0.1179 - val_loss: 3.6526\n",
      "Epoch 5/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.1174 - loss: 3.6537 - val_accuracy: 0.1179 - val_loss: 3.6507\n",
      "Epoch 6/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - accuracy: 0.1178 - loss: 3.6546 - val_accuracy: 0.1179 - val_loss: 3.6517\n",
      "Epoch 7/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - accuracy: 0.1176 - loss: 3.6506 - val_accuracy: 0.1179 - val_loss: 3.6515\n",
      "Epoch 8/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - accuracy: 0.1170 - loss: 3.6612 - val_accuracy: 0.1179 - val_loss: 3.6518\n",
      "Epoch 9/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - accuracy: 0.1169 - loss: 3.6548 - val_accuracy: 0.1179 - val_loss: 3.6537\n",
      "Epoch 10/10\n",
      "\u001b[1m6436/6436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - accuracy: 0.1177 - loss: 3.6522 - val_accuracy: 0.1179 - val_loss: 3.6507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4bf4759a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Eliminar filas con valores nan\n",
    "data = data.dropna()\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "X_title = data['PRIMARY DESCRIPTION'].values\n",
    "X_location = data['LOCATION'].apply(lambda x: [float(coordinate) for coordinate in x[1:-1].split(', ')])  # Convertir coordenadas en lista de flotantes\n",
    "y = data['SECONDARY DESCRIPTION'].values\n",
    "\n",
    "# Codificar etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Separar datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_location, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar coordenadas geográficas\n",
    "def calculate_distance(coord):\n",
    "    # Supongamos que utilizamos el origen como punto de referencia\n",
    "    reference_point = [0.0, 0.0]\n",
    "    return np.linalg.norm(np.array(coord) - np.array(reference_point))\n",
    "\n",
    "X_train_normalized = np.array([calculate_distance(coord) for coord in X_train]).reshape(-1, 1)\n",
    "X_test_normalized = np.array([calculate_distance(coord) for coord in X_test]).reshape(-1, 1)\n",
    "\n",
    "# Modelo de texto\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar el modelo\n",
    "model.fit(X_train_normalized, y_train, epochs=10, batch_size=32, validation_data=(X_test_normalized, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
